use bytesize::ByteSize;
use clap::{arg, Parser};
use flate2::bufread::GzDecoder;
use futures::TryStreamExt;
use http::Uri;
use humantime::format_duration;
use io_tee::TeeReader;
use sha2::{Digest, Sha256};
use soroban_ledger_snapshot::LedgerSnapshot;
use std::{
    collections::HashSet,
    fs::{self, OpenOptions},
    io::{self, BufReader, Read},
    path::PathBuf,
    str::FromStr,
    time::{Duration, Instant},
};
use stellar_xdr::curr::{
    BucketEntry, ConfigSettingEntry, ConfigSettingId, ContractExecutable, Frame, Hash, LedgerEntry,
    LedgerEntryData, LedgerKey, LedgerKeyAccount, LedgerKeyClaimableBalance,
    LedgerKeyConfigSetting, LedgerKeyContractCode, LedgerKeyContractData, LedgerKeyData,
    LedgerKeyLiquidityPool, LedgerKeyOffer, LedgerKeyTrustLine, LedgerKeyTtl, Limited, Limits,
    ReadXdr, ScContractInstance, ScVal,
};
use tokio_util::compat::FuturesAsyncReadCompatExt as _;

use soroban_env_host::xdr::{self};

use super::{
    config::{self, locator},
    network,
};
use crate::commands::config::data;

fn default_out_path() -> PathBuf {
    PathBuf::new().join("snapshot.json")
}

#[derive(Parser, Debug, Clone)]
#[group(skip)]
pub struct Cmd {
    /// The ledger sequence number to snapshot. Defaults to latest history archived ledger.
    #[arg(long)]
    ledger: Option<u32>,
    /// The out path that the snapshot is written to.
    #[arg(long, default_value=default_out_path().into_os_string())]
    out: PathBuf,
    /// Account IDs to filter by.
    #[arg(long = "account-id", help_heading = "FILTERS")]
    account_ids: Vec<String>,
    /// Contract IDs to filter by.
    #[arg(long = "contract-id", help_heading = "FILTERS")]
    contract_ids: Vec<String>,
    /// Contract IDs to filter by.
    #[arg(long = "wasm-hash", help_heading = "FILTERS")]
    wasm_hashes: Vec<String>,
    #[command(flatten)]
    locator: locator::Args,
    // #[command(flatten)]
    // network: network::Args,
}

#[derive(thiserror::Error, Debug)]
pub enum Error {
    #[error("cursor is not valid")]
    InvalidCursor,
    #[error("filepath does not exist: {path}")]
    InvalidFile { path: String },
    #[error("filepath ({path}) cannot be read: {error}")]
    CannotReadFile { path: String, error: String },
    #[error("cannot parse topic filter {topic} into 1-4 segments")]
    InvalidTopicFilter { topic: String },
    #[error("invalid segment ({segment}) in topic filter ({topic}): {error}")]
    InvalidSegment {
        topic: String,
        segment: String,
        error: xdr::Error,
    },
    #[error("cannot parse contract ID {contract_id}: {error}")]
    InvalidContractId {
        contract_id: String,
        error: stellar_strkey::DecodeError,
    },
    #[error("invalid JSON string: {error} ({debug})")]
    InvalidJson {
        debug: String,
        error: serde_json::Error,
    },
    #[error("invalid timestamp in event: {ts}")]
    InvalidTimestamp { ts: String },
    #[error("missing start_ledger and cursor")]
    MissingStartLedgerAndCursor,
    #[error("missing target")]
    MissingTarget,
    #[error(transparent)]
    Generic(#[from] Box<dyn std::error::Error>),
    #[error(transparent)]
    Io(#[from] io::Error),
    #[error(transparent)]
    Xdr(#[from] xdr::Error),
    #[error(transparent)]
    Serde(#[from] serde_json::Error),
    #[error(transparent)]
    Network(#[from] network::Error),
    #[error(transparent)]
    Locator(#[from] locator::Error),
    #[error(transparent)]
    Config(#[from] config::Error),
}

const CHECKPOINT_FREQUENCY: u32 = 64;

impl Cmd {
    pub async fn run(&self) -> Result<(), Error> {
        const BASE_URL: &str = "http://history.stellar.org/prd/core-live/core_live_001";

        let start = Instant::now();

        let history_url = if let Some(ledger) = self.ledger {
            // Check ledger is a checkpoint ledger and available in archives.
            let ledger_offset = (ledger + 1) % CHECKPOINT_FREQUENCY;
            if ledger_offset != 0 {
                println!(
                    "ledger {ledger} not a checkpoint ledger, use {} or {}",
                    ledger - ledger_offset,
                    ledger + (CHECKPOINT_FREQUENCY - ledger_offset),
                );
                return Ok(());
            }

            // Download history JSON file.
            let ledger_hex = format!("{ledger:08x}");
            let ledger_hex_0 = &ledger_hex[0..=1];
            let ledger_hex_1 = &ledger_hex[2..=3];
            let ledger_hex_2 = &ledger_hex[4..=5];
            format!("{BASE_URL}/history/{ledger_hex_0}/{ledger_hex_1}/{ledger_hex_2}/history-{ledger_hex}.json")
        } else {
            format!("{BASE_URL}/.well-known/stellar-history.json")
        };

        let history_url = Uri::from_str(&history_url).unwrap();
        println!("üåé Downloading history {history_url}");
        let https = hyper_tls::HttpsConnector::new();
        let response = hyper::Client::builder()
            .build::<_, hyper::Body>(https)
            .get(history_url)
            .await
            .unwrap();
        let body = hyper::body::to_bytes(response.into_body()).await.unwrap();
        let history = serde_json::from_slice::<History>(&body).unwrap();

        let ledger = history.current_ledger;
        let network_passphrase = &history.network_passphrase;
        let network_id = Sha256::digest(network_passphrase);
        println!("‚ÑπÔ∏è  Ledger: {ledger}");
        println!("‚ÑπÔ∏è  Network Passphrase: {network_passphrase}");
        println!("‚ÑπÔ∏è  Network ID: {}", hex::encode(network_id));

        // Prepare a flat list of buckets to read. They'll be ordered by their
        // level so that they can iterated higher level to lower level.
        let buckets = history
            .current_buckets
            .iter()
            .flat_map(|h| [h.curr.clone(), h.snap.clone()])
            .filter(|b| b != "0000000000000000000000000000000000000000000000000000000000000000")
            .collect::<Vec<_>>();

        // Track ledger keys seen, so that we can ignore old versions of
        // entries. Entries can appear in both higher level and lower level
        // buckets, and to get the latest version of the entry the version in
        // the higher level bucket should be used.
        let mut seen = HashSet::<LedgerKey>::new();

        // The snapshot is what will be written to file at the end. Fields will
        // be updated while parsing the history archive.
        // TODO: Update more of the fields.
        let mut snapshot = LedgerSnapshot {
            protocol_version: 0,
            sequence_number: ledger,
            timestamp: 0,
            network_id: network_id.into(),
            base_reserve: 1,
            min_persistent_entry_ttl: 0,
            min_temp_entry_ttl: 0,
            max_entry_ttl: 0,
            ledger_entries: Vec::new(),
        };

        let mut account_ids = self.account_ids.clone();
        let mut contract_ids = self.contract_ids.clone();
        let mut wasm_hashes = self.wasm_hashes.clone();
        for (i, bucket) in buckets.iter().enumerate() {
            // Defined where the bucket will be read from, either from cache on
            // disk, or streamed from the archive.
            let cache_path = data::bucket_dir()
                .unwrap()
                .join(format!("bucket-{bucket}.xdr"));
            let (read, stream): (Box<dyn Read + Sync + Send>, bool) = if cache_path.exists() {
                println!("ü™£  Loading cached bucket {i} {bucket}");
                let file = OpenOptions::new().read(true).open(&cache_path).unwrap();
                (Box::new(file), false)
            } else {
                let bucket_0 = &bucket[0..=1];
                let bucket_1 = &bucket[2..=3];
                let bucket_2 = &bucket[4..=5];
                let bucket_url = format!(
                    "{BASE_URL}/bucket/{bucket_0}/{bucket_1}/{bucket_2}/bucket-{bucket}.xdr.gz"
                );
                print!("ü™£  Downloading bucket {i} {bucket}");
                let bucket_url = Uri::from_str(&bucket_url).unwrap();
                let https = hyper_tls::HttpsConnector::new();
                let response = hyper::Client::builder()
                    .build::<_, hyper::Body>(https)
                    .get(bucket_url)
                    .await
                    .unwrap();
                if let Some(val) = response.headers().get("Content-Length") {
                    if let Ok(str) = val.to_str() {
                        if let Ok(len) = str.parse::<u64>() {
                            print!(" ({})", ByteSize(len));
                        }
                    }
                }
                println!();
                let read = tokio_util::io::SyncIoBridge::new(
                    response
                        .into_body()
                        .map_err(|e| io::Error::new(io::ErrorKind::Other, e))
                        .into_async_read()
                        .compat(),
                );
                (Box::new(read), true)
            };

            let cache_path = cache_path.clone();
            (seen, snapshot, account_ids, contract_ids, wasm_hashes) =
                tokio::task::spawn_blocking(move || {
                    let dl_path = cache_path.with_extension("dl");
                    let buf = BufReader::new(read);
                    let read: Box<dyn Read + Sync + Send> = if stream {
                        // When streamed from the archive the bucket will be
                        // uncompressed, and also be streamed to cache.
                        let gz = GzDecoder::new(buf);
                        let buf = BufReader::new(gz);
                        let file = OpenOptions::new()
                            .create(true)
                            .truncate(true)
                            .write(true)
                            .open(&dl_path)
                            .unwrap();
                        let tee = TeeReader::new(buf, file);
                        Box::new(tee)
                    } else {
                        Box::new(buf)
                    };
                    // Stream the bucket entries from the bucket, identifying
                    // entries that match the filters, and including only the
                    // entries that match in the snapshot.
                    let limited = &mut Limited::new(read, Limits::none());
                    let sz = Frame::<BucketEntry>::read_xdr_iter(limited);
                    let mut count_saved = 0;
                    for entry in sz {
                        let Frame(entry) = entry.unwrap();
                        let (key, val) = match entry {
                            BucketEntry::Liveentry(l) | BucketEntry::Initentry(l) => {
                                let k = data_into_key(&l);
                                (k, Some(l))
                            }
                            BucketEntry::Deadentry(k) => (k, None),
                            BucketEntry::Metaentry(m) => {
                                snapshot.protocol_version = m.ledger_version;
                                continue;
                            }
                        };
                        if seen.contains(&key) {
                            continue;
                        }
                        if let Some(val) = val {
                            let keep = match &val.data {
                                LedgerEntryData::Account(e) => {
                                    account_ids.contains(&e.account_id.to_string())
                                }
                                LedgerEntryData::Trustline(e) => {
                                    account_ids.contains(&e.account_id.to_string())
                                }
                                LedgerEntryData::ContractData(e) => {
                                    let keep = contract_ids.contains(&e.contract.to_string());
                                    // If a contract instance references
                                    // contract executable stored in another
                                    // ledger entry, add that ledger entry to
                                    // the filter so that Wasm for any filtered
                                    // contract is collected too.  TODO: Change
                                    // this to support Wasm ledger entries
                                    // appearing in earlier buckets after state
                                    // archival is rolled out.
                                    if keep && e.key == ScVal::LedgerKeyContractInstance {
                                        if let ScVal::ContractInstance(ScContractInstance {
                                            executable: ContractExecutable::Wasm(Hash(hash)),
                                            ..
                                        }) = e.val
                                        {
                                            let hash = hex::encode(hash);
                                            wasm_hashes.push(hash);
                                        }
                                    }
                                    keep
                                }
                                LedgerEntryData::ContractCode(e) => {
                                    let hash = hex::encode(e.hash.0);
                                    wasm_hashes.contains(&hash)
                                }
                                LedgerEntryData::Offer(_)
                                | LedgerEntryData::Data(_)
                                | LedgerEntryData::ClaimableBalance(_)
                                | LedgerEntryData::LiquidityPool(_)
                                | LedgerEntryData::ConfigSetting(_)
                                | LedgerEntryData::Ttl(_) => false,
                            };
                            seen.insert(key.clone());
                            if keep {
                                // Store the found ledger entry in the snapshot with
                                // a max u32 expiry. TODO: Change the expiry to come
                                // from the corresponding TTL ledger entry.
                                snapshot
                                    .ledger_entries
                                    .push((Box::new(key), (Box::new(val), Some(u32::MAX))));
                                count_saved += 1;
                            }
                        }
                    }
                    if stream {
                        fs::rename(&dl_path, &cache_path).unwrap();
                    }
                    if count_saved > 0 {
                        println!("üîé Found {count_saved} entries");
                    }
                    (seen, snapshot, account_ids, contract_ids, wasm_hashes)
                })
                .await
                .unwrap();
        }

        snapshot.write_file(&self.out).unwrap();
        println!(
            "üíæ Saved {} entries to {:?}",
            snapshot.ledger_entries.len(),
            self.out
        );

        let duration = Duration::from_secs(start.elapsed().as_secs());
        println!("‚úÖ Completed in {}", format_duration(duration));

        Ok(())
    }
}

#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, serde::Deserialize)]
#[serde(rename_all = "camelCase")]
struct History {
    current_ledger: u32,
    current_buckets: Vec<HistoryBucket>,
    network_passphrase: String,
}

#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, serde::Deserialize)]
#[serde(rename_all = "camelCase")]
struct HistoryBucket {
    curr: String,
    snap: String,
}

fn data_into_key(d: &LedgerEntry) -> LedgerKey {
    // TODO: Move this function into stellar-xdr.
    match &d.data {
        LedgerEntryData::Account(e) => LedgerKey::Account(LedgerKeyAccount {
            account_id: e.account_id.clone(),
        }),
        LedgerEntryData::Trustline(e) => LedgerKey::Trustline(LedgerKeyTrustLine {
            account_id: e.account_id.clone(),
            asset: e.asset.clone(),
        }),
        LedgerEntryData::Offer(e) => LedgerKey::Offer(LedgerKeyOffer {
            seller_id: e.seller_id.clone(),
            offer_id: e.offer_id,
        }),
        LedgerEntryData::Data(e) => LedgerKey::Data(LedgerKeyData {
            account_id: e.account_id.clone(),
            data_name: e.data_name.clone(),
        }),
        LedgerEntryData::ClaimableBalance(e) => {
            LedgerKey::ClaimableBalance(LedgerKeyClaimableBalance {
                balance_id: e.balance_id.clone(),
            })
        }
        LedgerEntryData::LiquidityPool(e) => LedgerKey::LiquidityPool(LedgerKeyLiquidityPool {
            liquidity_pool_id: e.liquidity_pool_id.clone(),
        }),
        LedgerEntryData::ContractData(e) => LedgerKey::ContractData(LedgerKeyContractData {
            contract: e.contract.clone(),
            key: e.key.clone(),
            durability: e.durability,
        }),
        LedgerEntryData::ContractCode(e) => LedgerKey::ContractCode(LedgerKeyContractCode {
            hash: e.hash.clone(),
        }),
        LedgerEntryData::ConfigSetting(e) => LedgerKey::ConfigSetting(LedgerKeyConfigSetting {
            config_setting_id: match e {
                ConfigSettingEntry::ContractMaxSizeBytes(_) => {
                    ConfigSettingId::ContractMaxSizeBytes
                }
                ConfigSettingEntry::ContractComputeV0(_) => ConfigSettingId::ContractComputeV0,
                ConfigSettingEntry::ContractLedgerCostV0(_) => {
                    ConfigSettingId::ContractLedgerCostV0
                }
                ConfigSettingEntry::ContractHistoricalDataV0(_) => {
                    ConfigSettingId::ContractHistoricalDataV0
                }
                ConfigSettingEntry::ContractEventsV0(_) => ConfigSettingId::ContractEventsV0,
                ConfigSettingEntry::ContractBandwidthV0(_) => ConfigSettingId::ContractBandwidthV0,
                ConfigSettingEntry::ContractCostParamsCpuInstructions(_) => {
                    ConfigSettingId::ContractCostParamsCpuInstructions
                }
                ConfigSettingEntry::ContractCostParamsMemoryBytes(_) => {
                    ConfigSettingId::ContractCostParamsMemoryBytes
                }
                ConfigSettingEntry::ContractDataKeySizeBytes(_) => {
                    ConfigSettingId::ContractDataKeySizeBytes
                }
                ConfigSettingEntry::ContractDataEntrySizeBytes(_) => {
                    ConfigSettingId::ContractDataEntrySizeBytes
                }
                ConfigSettingEntry::StateArchival(_) => ConfigSettingId::StateArchival,
                ConfigSettingEntry::ContractExecutionLanes(_) => {
                    ConfigSettingId::ContractExecutionLanes
                }
                ConfigSettingEntry::BucketlistSizeWindow(_) => {
                    ConfigSettingId::BucketlistSizeWindow
                }
                ConfigSettingEntry::EvictionIterator(_) => ConfigSettingId::EvictionIterator,
            },
        }),
        LedgerEntryData::Ttl(e) => LedgerKey::Ttl(LedgerKeyTtl {
            key_hash: e.key_hash.clone(),
        }),
    }
}
